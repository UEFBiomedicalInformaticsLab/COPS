% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clustering_pipeline.R
\name{clusteval_scoring}
\alias{clusteval_scoring}
\title{Scoring of dimensionality reduction and clustering pipeline output}
\usage{
clusteval_scoring(
  input,
  by = c("datname", "drname", "k", "m"),
  wsum = TrainStabilityJaccard + Silhouette,
  chisq_significance_level = 0.05,
  summarise = TRUE
)
}
\arguments{
\item{input}{\code{\link{dimred_clusteval_pipeline}} output}

\item{by}{character vector containing column names to group analysis by}

\item{wsum}{an expression that indicates how a combined score is computed}

\item{chisq_significance_level}{p-value cutoff for computing rejection rate of \code{chisq.test}}

\item{summarise}{If FALSE, adds \code{"run"} and \code{"fold"} to \code{by}. By default the metrics 
are averaged across runs and folds.}
}
\value{
Returns a \code{list} containing a \code{data.frame} \code{$all} of all scores and
        a single row \code{$best} with the best score according to \code{wsum}.
}
\description{
Computes averages of metrics from pipeline output and also returns the
best combination based on a weighted sum of metrics.
}
\details{
Metrics are renamed for convenience: 
\itemize{
  \item [Train/Test]Stability[Jaccard/ARI/NMI]
  \item [NMI/ARI/ChisqRR].<batch>
  \item [NMI/ARI].<subtype>
  \item ...
}
}
